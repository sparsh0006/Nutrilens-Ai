# ğŸ NutriLens AI

**Visual Nutrition Awareness Agent â€” Honest, Uncertainty-Aware, Evaluation-Driven**

> Upload a meal photo. Get nutrition ranges, not false precision. Build awareness, not obsession.

NutriLens AI helps users develop healthier eating awareness through computer vision and a multi-agent AI pipeline. It provides **range-based nutrition estimates**, **confidence scores**, and **reflective prompts** â€” never exact calorie counts or prescriptive dietary advice.

Every AI decision is traced, evaluated, and improvable through **Opik by Comet**.

ğŸ”— **[Live Demo](https://nutrilens-ai-brown.vercel.app/)** Â· ğŸ“Š **[Opik Workspace: among-gaming](https://www.comet.com/opik)** Â· ğŸ¥ **Health, Fitness & Wellness Track** Â· ğŸ† **Best Use of Opik**

---

## ğŸ¯ Why NutriLens AI?

Most nutrition apps give you a single number â€” "this meal is 487 calories" â€” creating **false precision**. A grilled chicken breast could be 165â€“220 kcal depending on portion size, cooking method, and whether the skin is on.

NutriLens AI takes a different approach:

| Traditional Apps | NutriLens AI |
|---|---|
| Exact calorie counts | Range estimates (165â€“220 kcal) |
| Black-box results | Confidence scores + variability factors |
| "Eat this, not that" | Reflective questions for self-discovery |
| No transparency | Every AI decision traced in Opik |

**The goal isn't calorie counting â€” it's building awareness.**

---

## ğŸ¥ Health, Fitness & Wellness

NutriLens AI is designed for the **Health, Fitness & Wellness** track with responsible AI at its core:

- **Range Estimates, Not Exact Values** â€” Reflects real-world uncertainty in nutrition (portion size, preparation method, ingredient variations)
- **Non-Prescriptive Tone** â€” Never tells users what to eat or avoid; focuses on awareness and self-discovery
- **Reflective Prompts** â€” Encourages mindful eating through open-ended questions across awareness, goals, habits, and alternatives
- **Supportive Habit Nudges** â€” Celebrates positive choices and gently suggests variety without judgment
- **Safety Disclaimers** â€” Clearly states this is for educational purposes only, not medical or dietary advice
- **Tone Safety Monitoring** â€” An LLM-as-judge evaluator actively checks every response for prescriptive language

---

## ğŸ—ï¸ Multi-Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Uploads   â”‚
â”‚  Meal Image     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Food Recognition Agent (GPT-4o Vision) â”‚
â”‚  Identifies foods + confidence scores       â”‚
â”‚  â†’ Opik Trace: food-recognition-llm-call    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Nutrition Estimation Agent (GPT-4o-mini)â”‚
â”‚  Range-based estimates + variability factorsâ”‚
â”‚  â†’ Opik Trace: nutrition-estimation-llm-callâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤” Reflection Agentâ”‚  â”‚ ğŸ’¡ Habit Nudge Agentâ”‚
â”‚ Awareness questionsâ”‚  â”‚ Supportive nudges  â”‚
â”‚ â†’ Opik Traced      â”‚  â”‚ â†’ Opik Traced      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  âš–ï¸ LLM-as-Judge Evaluation  â”‚
      â”‚  Hallucination Â· Clarity Â·   â”‚
      â”‚  Tone Safety                 â”‚
      â”‚  â†’ 3 Opik Evaluation Traces  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  ğŸ“ User Feedback Loop       â”‚
      â”‚  Corrections â†’ Opik Logging  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Details

| Agent | Model | Purpose | Key Output |
|---|---|---|---|
| Food Recognition | GPT-4o Vision | Identify foods from images | Food items + confidence (0â€“1) + category |
| Nutrition Estimation | GPT-4o-mini | Estimate nutrition ranges | Calorie/protein/carb/fat ranges + variability factors |
| Reflection | GPT-4o-mini | Generate awareness prompts | 3â€“5 questions across awareness, goals, habits, alternatives |
| Habit Nudge | GPT-4o-mini | Supportive suggestions | 2â€“3 positive/neutral/suggestion nudges |

---

## ğŸ” Best Use of Opik â€” Evaluation & Observability

Opik is not an add-on â€” it's central to how NutriLens AI is built, tested, and improved.

### Full Agent Tracing with `opik-openai`

Every agent creates a parent trace with `opikClient.trace()`, then uses `trackOpenAI()` from `opik-openai` with `parent: trace` to automatically capture:

- **Model name, prompts, and completions** as child spans
- **Token usage and cost** per LLM call
- **Latency** for each agent
- **Errors** with full stack context

```typescript
// Each agent creates a traced OpenAI client
const trace = opikClient.trace({ name: 'food-recognition-agent', ... });
const openai = trackOpenAI(new OpenAI({ apiKey }), {
  client: opikClient,
  parent: trace,  // LLM call appears as child span
  generationName: 'food-recognition-llm-call',
});
```

### 3 LLM-as-Judge Evaluations

Every analysis is automatically evaluated (async, non-blocking) on three dimensions:

| Metric | What It Measures | Why It Matters |
|---|---|---|
| **Hallucination Score** | Are nutrition claims factually grounded? | Prevents false health information |
| **Clarity Score** | Is the output well-structured and understandable? | Users need clear, actionable information |
| **Tone Safety Score** | Does it avoid prescriptive dietary advice? | Critical for the Health track â€” safety first |

```
Evaluation metrics: {
  hallucinationScore: 1,
  clarityScore: 1,
  toneScore: 1,
  confidenceCalibration: 0.5,
  overallQuality: 1
}
```

### User Feedback Loop

User corrections (food identification, portion sizes, satisfaction ratings) are logged as separate Opik traces linked to the original analysis via `analysisId`, creating a closed loop for continuous improvement.

### Opik Dashboard Visibility

All traces are visible at:
- **Workspace:** `among-gaming`
- **Project:** `nutrilens-ai`
- **Traces include:** food-recognition-agent, nutrition-estimation-agent, reflection-agent, habit-nudge-agent, evaluation-llm-call (Ã—3), user-feedback

---

## âœ¨ Key Features

- ğŸ“¸ **Image-Based Analysis** â€” Upload meal photos for instant multi-agent analysis
- ğŸ“Š **Range Estimates** â€” Nutrition ranges (not exact values) reflecting real uncertainty
- ğŸ¤” **Reflection Prompts** â€” Open-ended questions encouraging healthy self-awareness
- ğŸ’¡ **Habit Nudges** â€” Supportive, non-prescriptive suggestions celebrating positive choices
- ğŸ” **Full Opik Tracing** â€” Every agent call traced with spans via `opik-openai` integration
- âš–ï¸ **LLM-as-Judge** â€” 3 automated evaluation metrics on every analysis
- ğŸ“ **Feedback Loop** â€” User corrections logged to Opik for continuous improvement
- ğŸ¨ **Modern UI** â€” Clean, responsive Next.js interface with Tailwind CSS

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- OpenAI API Key
- Opik API Key ([comet.com/opik](https://www.comet.com/opik))
- MongoDB (optional)

### Installation

```bash
git clone https://github.com/sparsh0006/Nutrilens-Ai.git
cd nutrilens-ai
npm install
cp .env.example .env.local
```

### Environment Variables

```env
# Opik
OPIK_API_KEY=your_opik_api_key
OPIK_URL_OVERRIDE=https://www.comet.com/opik/api
OPIK_PROJECT_NAME=nutrilens-ai
OPIK_WORKSPACE_NAME=your_workspace

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# MongoDB (optional)
MONGODB_URI=mongodb://localhost:27017/nutrilens

# App
NEXT_PUBLIC_API_URL=http://localhost:3000
NODE_ENV=development
```

### Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

---

## ğŸ“¦ Project Structure

```
nutrilens-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze/route.ts          # Multi-agent pipeline endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ feedback/route.ts         # Feedback collection â†’ Opik
â”‚   â”‚   â”‚   â””â”€â”€ health/route.ts           # Health check
â”‚   â”‚   â”œâ”€â”€ page.tsx                      # Main UI
â”‚   â”‚   â””â”€â”€ layout.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ImageUpload.tsx               # Drag-and-drop image upload
â”‚   â”‚   â”œâ”€â”€ NutritionResults.tsx          # Range-based results display
â”‚   â”‚   â”œâ”€â”€ ReflectionPrompts.tsx         # Reflection questions UI
â”‚   â”‚   â””â”€â”€ FeedbackForm.tsx              # User feedback form
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ foodRecognitionAgent.ts   # GPT-4o Vision + Opik trace
â”‚   â”‚   â”‚   â”œâ”€â”€ nutritionEstimationAgent.ts # Range estimates + Opik trace
â”‚   â”‚   â”‚   â”œâ”€â”€ reflectionAgent.ts        # Awareness prompts + Opik trace
â”‚   â”‚   â”‚   â””â”€â”€ habitNudgeAgent.ts        # Supportive nudges + Opik trace
â”‚   â”‚   â”œâ”€â”€ opik/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.ts                # Opik client + traceAgent wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluators.ts            # 3 LLM-as-judge metrics
â”‚   â”‚   â”‚   â””â”€â”€ tracers.ts              # Tracing utilities
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â””â”€â”€ utils.ts
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ Meal.ts                       # MongoDB meal schema
â”‚       â””â”€â”€ Feedback.ts                   # MongoDB feedback schema
â””â”€â”€ package.json
```

---

## ğŸ” Safety & Responsible AI

| Principle | Implementation |
|---|---|
| No Medical Claims | Disclaimers in UI header and footer; agents instructed to avoid medical advice |
| Range Estimates | All nutrition values shown as minâ€“max ranges, never single numbers |
| Confidence Scores | Every food item shows identification confidence (0â€“100%) |
| Non-Prescriptive | Reflection agent uses open-ended questions; nudge agent never commands |
| Tone Monitoring | LLM-as-judge tone safety evaluator runs on every analysis |
| User Autonomy | Feedback system empowers users to correct and improve results |

---

## ğŸ› ï¸ Tech Stack

- **Framework:** Next.js 14 + TypeScript
- **AI Models:** OpenAI GPT-4o (vision), GPT-4o-mini (text)
- **Observability:** Opik SDK + opik-openai integration
- **Database:** MongoDB + Mongoose (optional)
- **Styling:** Tailwind CSS
- **Deployment:** Vercel

---

## ğŸ“§ Links

- **Live Demo:** [nutrilens-ai-brown.vercel.app](https://nutrilens-ai-brown.vercel.app/)
- **GitHub:** [github.com/sparsh0006/Nutrilens-Ai](https://github.com/sparsh0006/Nutrilens-Ai)
- **Opik Docs:** [comet.com/docs/opik](https://www.comet.com/docs/opik/)

---

Built with â¤ï¸ for the **Health, Fitness & Wellness** track + **Best Use of Opik**